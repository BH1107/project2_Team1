{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nnictl create --config config.yaml --port 8080\n",
    "\n",
    "from src.data import CostomerDataset, CostomerDataModule\n",
    "from src.utils import convert_category_into_integer\n",
    "from src.model.mlp import Model\n",
    "from src.training import CostomerModule\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import nni\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.trainer import Trainer\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\김정훈\\AppData\\Local\\Temp\\ipykernel_17628\\3009880447.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(\"./model/mlp.pth\", map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  7126.00, TN:  0.00, FP:  2825.00, FN:  0.00\n",
      "precision:  0.72, recall:  1.00, f1:  0.83, accuracy:  0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      1.00      0.83      7126\n",
      "         1.0       0.00      0.00      0.00      2825\n",
      "\n",
      "    accuracy                           0.72      9951\n",
      "   macro avg       0.36      0.50      0.42      9951\n",
      "weighted avg       0.51      0.72      0.60      9951\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\김정훈\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\김정훈\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\김정훈\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from src.data import CostomerDataset, CostomerDataModule\n",
    "from src.model.mlp import Model\n",
    "from src.training import CostomerModule\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def main(configs):\n",
    "    # 데이터 로드 및 전처리\n",
    "    costomer = pd.read_csv('./data/train.csv')\n",
    "    costomer = costomer.dropna()\n",
    "\n",
    "    # 범주형 변수를 숫자로 변환하는 함수\n",
    "    costomer, _ = convert_category_into_integer(costomer, (\n",
    "        'Churn', 'ServiceArea', 'ChildrenInHH', 'HandsetRefurbished', \n",
    "        'HandsetWebCapable', 'TruckOwner', 'RVOwner', 'Homeownership', \n",
    "        'BuysViaMailOrder', 'RespondsToMailOffers', 'OptOutMailings', \n",
    "        'NonUSTravel', 'OwnsComputer', 'HasCreditCard', 'NewCellphoneUser', \n",
    "        'NotNewCellphoneUser', 'OwnsMotorcycle', 'HandsetPrice', \n",
    "        'MadeCallToRetentionTeam', 'CreditRating', 'PrizmCode', \n",
    "        'Occupation', 'MaritalStatus'\n",
    "    ))\n",
    "    costomer = costomer.astype(np.float32)\n",
    "\n",
    "    # Train/Validation/Test Split\n",
    "    train, temp = train_test_split(costomer, test_size=0.4, random_state=seed)\n",
    "    valid, test = train_test_split(temp, test_size=0.5, random_state=seed)\n",
    "\n",
    "    # 표준화 작업\n",
    "    standard_scaler = StandardScaler()\n",
    "\n",
    "    other_columns = ['MonthlyRevenue', 'MonthlyMinutes', 'TotalRecurringCharge', \n",
    "                     'DirectorAssistedCalls', 'OverageMinutes', 'RoamingCalls', \n",
    "                     'PercChangeMinutes', 'PercChangeRevenues', 'DroppedCalls', \n",
    "                     'BlockedCalls', 'UnansweredCalls', 'CustomerCareCalls', \n",
    "                     'ThreewayCalls', 'ReceivedCalls', 'OutboundCalls', \n",
    "                     'InboundCalls', 'PeakCallsInOut', 'OffPeakCallsInOut', \n",
    "                     'DroppedBlockedCalls', 'CallForwardingCalls', \n",
    "                     'CallWaitingCalls', 'MonthsInService', 'UniqueSubs', \n",
    "                     'ActiveSubs', 'Handsets', 'HandsetModels', \n",
    "                     'CurrentEquipmentDays', 'AgeHH1', 'AgeHH2', 'RetentionCalls', \n",
    "                     'RetentionOffersAccepted', 'ReferralsMadeBySubscriber', \n",
    "                     'IncomeGroup', 'AdjustmentsToCreditRating']\n",
    "\n",
    "    train.loc[:, other_columns] = standard_scaler.fit_transform(train.loc[:, other_columns])\n",
    "    valid.loc[:, other_columns] = standard_scaler.transform(valid.loc[:, other_columns])\n",
    "    test.loc[:, other_columns] = standard_scaler.transform(test.loc[:, other_columns])\n",
    "\n",
    "    # Dataset과 DataLoader 설정\n",
    "    train_dataset = CostomerDataset(train)\n",
    "    valid_dataset = CostomerDataset(valid)\n",
    "    test_dataset = CostomerDataset(test)\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=configs.get('batch_size'),\n",
    "    )\n",
    "\n",
    "    configs.update({'input_dim': len(costomer.columns)-1})\n",
    "    \n",
    "    # 모델 로드\n",
    "    model = Model(configs)\n",
    "    # model.load_state_dict(torch.load('./model/mlp.pth'))  # 모델 파라미터 불러오기\n",
    "    model_state_dict = torch.load(\"./model/mlp.pth\", map_location=device)\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    # model.eval()  # 평가 모드로 전환\n",
    "\n",
    "    # prediction\n",
    "    preds = []\n",
    "    gts = []\n",
    "    for batch in test_dataloader:\n",
    "        X = batch.get('X')\n",
    "        y = batch.get('y')\n",
    "        # X = torch.from_numpy(batch.iloc[idx].drop('Churn').values).float()\n",
    "        # y = torch.Tensor([batch.iloc[idx].Churn]).float()\n",
    "        with torch.no_grad():  # 예측 시에는 그래디언트 필요 없음\n",
    "            pred = model(X)\n",
    "            print(pred)\n",
    "            preds.append(pred.argmax(dim=-1))\n",
    "            gts.append(y)\n",
    "\n",
    "    # 텐서 리스트를 합침\n",
    "    preds = torch.cat(preds)\n",
    "    gts = torch.cat(gts)\n",
    "\n",
    "    # Confusion Matrix 및 성능 지표 계산\n",
    "    confusion_matrix_result = confusion_matrix(gts.cpu().numpy(), preds.cpu().numpy())\n",
    "    TP = confusion_matrix_result[0, 0]\n",
    "    FN = confusion_matrix_result[0, 1]\n",
    "    FP = confusion_matrix_result[1, 0]\n",
    "    TN = confusion_matrix_result[1, 1]\n",
    "\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \n",
    "    print(f'TP: {TP: .2f}, TN: {TN: .2f}, FP: {FP: .2f}, FN: {FN: .2f}')\n",
    "\n",
    "    print(f'precision: {precision: .2f}, recall: {recall: .2f}, f1: {f1: .2f}, accuracy: {accuracy: .2f}')\n",
    "    print(classification_report(gts, preds))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 사용 가능한 GPU가 있는 경우 'cuda', 그렇지 않으면 'cpu' 사용\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    # hyperparameter\n",
    "    with open('./configs.json', 'r') as file:\n",
    "        configs = json.load(file)\n",
    "    configs.update({'device': device})\n",
    "\n",
    "    # seed 설정\n",
    "    seed = configs.get('seed')\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # CUDA 설정\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    main(configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "51035    0\n",
       "51037    0\n",
       "51040    0\n",
       "51041    1\n",
       "51043    0\n",
       "Name: Churn, Length: 49752, dtype: int32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costomer = pd.read_csv('./data/train.csv')\n",
    "costomer = costomer.dropna()\n",
    "costomer.Churn = np.where(costomer.Churn == \"Yes\", 1, 0)\n",
    "costomer.Churn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
